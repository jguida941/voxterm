# Codex Voice Architecture & Operations Guide

## ğŸ—ï¸ System Overview

Codex Voice is a voice-controlled interface for the Codex AI assistant, featuring a Rust TUI (Terminal User Interface) with real-time audio capture, speech-to-text transcription, and AI interaction.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     USER INTERACTION                     â”‚
â”‚                    (Voice + Keyboard)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚                           â”‚
                      â–¼                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      RUST TUI (Main)        â”‚   â”‚ Voice Input (Ctrl+R)      â”‚
â”‚   rust_tui/src/main.rs      â”‚   â”‚  â€¢ Captures audio         â”‚
â”‚   - Terminal UI (ratatui)   â”‚â—„â”€â”€â”¤  â€¢ Transcribes w/ Whisper â”‚
â”‚   - Event loop              â”‚   â”‚  â€¢ Sends prompt to Codex  â”‚
â”‚   - Status display          â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AUDIO PIPELINE                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚ RUST NATIVE  â”‚     â”‚   PYTHON     â”‚                 â”‚
â”‚  â”‚   (FAST)     â”‚ OR  â”‚  FALLBACK    â”‚                 â”‚
â”‚  â”‚              â”‚     â”‚   (SLOW)     â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚                                                          â”‚
â”‚  Rust Path:                Python Path:                 â”‚
â”‚  1. audio.rs (cpal)        1. codex_voice.py           â”‚
â”‚  2. Resample to 16kHz      2. pyaudio recording        â”‚
â”‚  3. stt.rs (whisper-rs)    3. whisper transcription    â”‚
â”‚  4. Direct to Codex        4. JSON response            â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CODEX INTEGRATION                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚         PTY Session Manager           â”‚              â”‚
â”‚  â”‚      (pty_session.rs)                â”‚              â”‚
â”‚  â”‚   - Spawns Codex process             â”‚              â”‚
â”‚  â”‚   - Manages I/O streams              â”‚              â”‚
â”‚  â”‚   - Handles terminal queries         â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
codex_voice/
â”‚
â”œâ”€â”€ rust_tui/                   # Main Rust TUI application
â”‚   â”œâ”€â”€ Cargo.toml             # Rust dependencies
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main.rs            # Entry point, TUI setup
â”‚   â”‚   â”œâ”€â”€ app.rs             # Application state & logic
â”‚   â”‚   â”œâ”€â”€ ui.rs              # Terminal UI rendering
â”‚   â”‚   â”œâ”€â”€ audio.rs           # Audio recording (cpal)
â”‚   â”‚   â”œâ”€â”€ stt.rs             # Speech-to-text (whisper-rs)
â”‚   â”‚   â”œâ”€â”€ voice.rs           # Voice capture orchestration
â”‚   â”‚   â”œâ”€â”€ pty_session.rs     # PTY/terminal management
â”‚   â”‚   â”œâ”€â”€ config.rs          # Configuration & CLI args
â”‚   â”‚   â””â”€â”€ utf8_safe.rs       # UTF-8 safe string ops
â”‚   â”‚
â”‚   â””â”€â”€ target/
â”‚       â””â”€â”€ release/
â”‚           â””â”€â”€ rust_tui       # Compiled binary
â”‚
â”œâ”€â”€ models/                     # Whisper AI models
â”‚   â”œâ”€â”€ ggml-tiny.en.bin      # Fastest (74MB)
â”‚   â””â”€â”€ ggml-base.en.bin      # Better quality (141MB)
â”‚
â”œâ”€â”€ codex_voice.py             # Python fallback pipeline (legacy but available)
â”œâ”€â”€ scripts/                    # Helper scripts (launchers, PTY utilities)
â””â”€â”€ docs/guides/architecture_overview.md  # This guide

```

## ğŸš€ Quick Start Commands

### Build & Run
```bash
# Navigate to project
cd /Users/jguida941/new_github_projects/codex_voice/rust_tui

# Build (debug mode - slow but with symbols)
cargo build

# Build (release mode - fast, optimized)
cargo build --release

# Run directly
cargo run --release

# Or run compiled binary
./target/release/rust_tui
```

### Download Whisper Models (Required for Rust path)
```bash
# Tiny model (fastest, 74MB, lower quality)
curl -L "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-tiny.en.bin" \
     -o models/ggml-tiny.en.bin

# Base model (slower, 141MB, better quality)
curl -L "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base.en.bin" \
     -o models/ggml-base.en.bin

# Small model (even slower, 488MB, good quality)
curl -L "https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-small.en.bin" \
     -o models/ggml-small.en.bin
```

## âš™ï¸ Configuration Options

### Command Line Arguments
```bash
# Show all options (from rust_tui/)
cargo run --release -- --help

# Common flags
--seconds 5                          # Recording duration (default 5s)
--lang en                            # Whisper language/tokens
--input-device "MacBook Pro Microphone"   # Force a specific microphone
--list-input-devices                 # Enumerate microphones and exit
--log-timings                        # Emit timing breakdown to log file
--whisper-model-path ../models/ggml-base.en.bin   # GGML file for whisper-rs
--codex-cmd /path/to/codex           # Codex CLI binary
--codex-arg="--danger-full-access"   # Forward extra Codex CLI flags safely
--no-python-fallback                 # Disable Python pipeline (error if native fails)
```

### Examples
```bash
# Fast setup (2 s recording, tiny model)
cargo run --release -- \
  --seconds 2 \
  --whisper-model-path ../models/ggml-tiny.en.bin

# High quality (5 s recording, base model)
cargo run --release -- \
  --seconds 5 \
  --whisper-model-path ../models/ggml-base.en.bin

# Debug performance issues with timings enabled
cargo run --release -- \
  --log-timings \
  --whisper-model-path ../models/ggml-base.en.bin

# Use a specific microphone and custom Codex flag
cargo run --release -- \
  --input-device "MacBook Pro Microphone" \
  --codex-arg="--danger-full-access" \
  --whisper-model-path ../models/ggml-base.en.bin
```

## ğŸ¤ Voice Pipeline Decision Tree

```
User presses Ctrl+R (or auto voice mode triggers)
    â”‚
    â–¼
Is Whisper model available?
    â”‚
    â”œâ”€ YES â”€â†’ Use RUST NATIVE path
    â”‚         â”‚
    â”‚         â”œâ”€ Record with cpal (audio.rs)
    â”‚         â”œâ”€ Resample to 16kHz mono
    â”‚         â”œâ”€ Transcribe with whisper-rs (stt.rs)
    â”‚         â””â”€ Send to Codex
    â”‚
    â””â”€ NO â”€â”€â†’ Use PYTHON FALLBACK path
              â”‚
              â”œâ”€ Spawn Python subprocess
              â”œâ”€ Run codex_voice.py
              â”œâ”€ Parse JSON response
              â””â”€ Send to Codex
```

## ğŸ”§ Key Components

### 1. Main Application (`app.rs`)
- Manages application state
- Handles keyboard/voice events
- Coordinates between UI and backend
- UTF-8 safe text processing

### 2. Audio Recording (`audio.rs`)
- Uses `cpal` for cross-platform audio capture
- Downmixes to mono and recenters unsigned samples
- Resamples to 16 kHz (Whisper requirement)
- Two resamplers:
  - High-quality: Rubato (feature-gated)
  - Basic: FIR + linear interpolation

### 3. Speech-to-Text (`stt.rs`)
- Uses `whisper-rs` bindings
- Loads GGML models
- Runs inference on CPU
- Returns transcribed text

### 4. Voice Orchestration (`voice.rs`)
- Spawns background worker thread
- Tries Rust path first
- Falls back to Python if needed
- Reports status to UI

### 5. PTY Session (`pty_session.rs`)
- Creates pseudo-terminal
- Spawns Codex process
- Handles terminal control sequences
- Manages I/O streams

### 6. UI Rendering (`ui.rs`)
- Uses `ratatui` for TUI
- Real-time status updates
- UTF-8 safe text display
- No text wrapping (avoids ratatui bug)

#### Key Bindings
- `Ctrl+R` â€“ start a voice capture immediately
- `Ctrl+V` â€“ toggle automatic voice capture after each Codex reply
- `Enter` â€“ send the current prompt to Codex
- `Esc` â€“ clear the input buffer
- `PageUp/PageDown` or `K/J` â€“ scroll Codex output
- `Ctrl+C` â€“ exit the TUI

## ğŸ› Debug & Logs

### Log File Location
```bash
# Debug log (automatic)
/tmp/codex_voice_tui.log

# View live logs
tail -f /tmp/codex_voice_tui.log

# Check for errors
grep -i error /tmp/codex_voice_tui.log

# Check pipeline path
grep -E "(Rust pipeline|Python fallback)" /tmp/codex_voice_tui.log
```

### Performance Analysis
```bash
# Run with timing logs
cargo run --release -- --log-timings --whisper-model-path ../models/ggml-base.en.bin

# Check timings in log
grep "timing|phase=voice_capture" /tmp/codex_voice_tui.log

# Format: record_s=X.XXX|stt_s=X.XXX|chars=XXX
# record_s = recording duration
# stt_s = transcription time
# chars = transcript length
```

## ğŸš„ Performance Optimization

### Current Bottlenecks
1. **Whisper inference** (~1-3s on CPU)
2. **Recording duration** (default 3s)
3. **Python subprocess** (if fallback)
4. **Model size** (larger = slower)

### Speed Improvements
```bash
# Use tiny model (fastest)
--whisper-model-path ../models/ggml-tiny.en.bin

# Reduce recording time
--seconds 2

# Ensure release build
cargo build --release

# Prefer native Rust path (avoid Python fallback)
--no-python-fallback

# Select the best audio device
--list-input-devices
--input-device "Your Best Mic"
```

### Build Features
```bash
# With high-quality audio resampling
cargo build --release --features high-quality-audio

# Minimal build (faster compile, basic resampling)
cargo build --release --no-default-features
```

## ğŸ§ª Testing

### Unit Tests
```bash
cargo test
cargo test --features high-quality-audio
cargo test voice::tests::python_fallback_returns_trimmed_transcript
```

### Manual Integration Test
```bash
# Enumerate microphones
cargo run --release -- --list-input-devices

# Full TUI + voice capture
cargo run --release -- \
  --seconds 5 \
  --whisper-model-path ../models/ggml-base.en.bin
```
1. Press `Ctrl+R`, speak, and confirm the transcript appears in the prompt.
2. Press `Enter` to send it to Codex and verify the response in the output pane.
3. Review `${TMPDIR}/codex_voice_tui.log` for `timing|phase=voice_capture` entries.

## ğŸ“Š Status Line Indicators

- **Ready. Press Ctrl+R...** â€“ waiting for input
- **Recording voice...** â€“ `audio.rs` actively capturing samples
- **Transcribing...** â€“ Whisper inference running
- **Rust pipeline/Python fallback** â€“ which STT path produced the transcript
- **Errors** â€“ surfaced directly (e.g., microphone permissions)

## ğŸ¯ Common Issues & Solutions

### "Fallback to Python pipeline" when native should work
- Ensure `--whisper-model-path` points to an existing GGML file.
- Check `cargo run --bin test_audio` to confirm the microphone captures anything.

### No devices listed / permission errors
- On macOS grant microphone permission to your terminal (System Settings â†’ Privacy & Security â†’ Microphone).
- Provide a device explicitly with `--input-device` to avoid default device confusion.

### Voice capture feels slow
- Reduce `--seconds` (recording duration) until silence-aware capture lands.
- Enable `--log-timings` and attach the log when filing performance bugs.

### Issue: Panic with large byte index
**Solution:** Already fixed! Our patches handle:
- UTF-8 safe string slicing
- Saturating arithmetic
- Mutex poisoning recovery
- Terminal query responses

### Issue: Slow transcription
**Solution:** Use the tiny model + shorter recording
```bash
cargo run --release -- \
  --seconds 2 \
  --whisper-model-path ../models/ggml-tiny.en.bin
```

## ğŸ“ Development Workflow

```bash
# 1. Make code changes
vim src/app.rs

# 2. Check compilation
cargo check

# 3. Run tests
cargo test

# 4. Build release
cargo build --release

# 5. Test manually
cargo run --release -- --whisper-model-path ../models/ggml-base.en.bin

# 6. Check logs
tail -f /tmp/codex_voice_tui.log
```

## ğŸ”® Future Improvements

- [ ] GPU acceleration for Whisper
- [ ] Streaming transcription
- [ ] Voice activity detection (VAD)
- [ ] Wake word detection
- [ ] Multi-language support
- [ ] Noise suppression
- [ ] Custom Whisper fine-tuning

---

**Quick Reference Card:**

```bash
# BUILD
cd rust_tui && cargo build --release

# RUN
cargo run --release -- --whisper-model-path ../models/ggml-base.en.bin

# TEST VOICE
Press Ctrl+R, speak, verify transcript, press Enter

# CHECK LOGS
tail -f /tmp/codex_voice_tui.log

# FAST MODE (short capture + tiny model)
cargo run --release -- \
  --seconds 2 \
  --whisper-model-path ../models/ggml-tiny.en.bin
```
